---
title: "Long Read Tutorial"
author: "Jorden Rabasco"
date: "6/29/2022"
output: html_document
---

```{r, include = FALSE}
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE)
```

This tutorial is intended for those that wish to analyze their long read sequences generated from Pacbio sequencing. The output from this workflow will consist of assigned taxonomies of your ASVs generated by dada2. This tutorial also assumes a working version of R 4.2.0

Lets begin.


##  Initial Set up

In the initial set up we will have to prep the reads for filtering and primer trimming. Prior to this you will need to run the below code at the command line. This will convert the bam file into a fastq file that can then be further analyzed downstream. 

ccs --pbi --force --logLevel=DEBUG --numThreads=16 --minSnr=3.75 --minReadScore=0.65 --maxLength=7000 --minLength=10 --minPasses=3 --minZScore=-5 --maxDropFraction=0.34 --minPredictedAccuracy=0.999 subreads.bam ccs.bam

Prior to any R processing please make sure to install dada2 appropriately as well as the dependencies. The appropriate information can be found here: <https://benjjneb.github.io/dada2/dada-installation.html>

```{r, message = FALSE, warning = FALSE, eval=FALSE, include = FALSE}
install.packages("devtools", repos='http://cran.us.r-project.org', dependencies = TRUE)
library("devtools")
devtools::install_github("benjjneb/dada2", ref="v1.20")
```

Once dada2 is installed load the library and check the version. Make sure thea you are using the latest version of dada2 as some fixes may have been implemented in later releases. This tutorial ultitzes version 1.20.0 of the dada2 package.
```{r, message = FALSE, warning = FALSE, include = FALSE}
library(dada2);packageVersion("dada2")
```

```{r, message = FALSE, warning = FALSE, include = FALSE}
library(Biostrings);packageVersion("Biostrings")
library(ShortRead);packageVersion("ShortRead")
library(ggplot2);packageVersion("ggplot2")
library(reshape2);packageVersion("reshape2")
library(RColorBrewer);packageVersion("RColorBrewer")

library(BiocGenerics);packageVersion("BiocGenerics")
library(S4Vectors);packageVersion("S4Vectors")
library(Biostrings);packageVersion("Biostrings")
library(Biobase);packageVersion("Biobase")
library(MatrixGenerics);packageVersion("MatrixGenerics")
```


## Pathing setup

In this section you will need to make some changes. After you downloaded the tutorial zip file you will need to change "base_path" variable to whereever you have it downloaded. If you are on a windows machine you can right click and look in properties for the correct path and if you are on a mac you can use the pwd command in the terminal. 
Note: After you have concluded the tutorial and wish to change run this pipeline on your own data change the location of the variable "fn" to the CCS sequences that you would like to process. 
```{r Pathing Set-up, message = FALSE, warning = FALSE}

base_path <- "C:/Users/Jorden/Desktop" #output generation location
pac_path <- file.path(base_path, "v2_long_read_tutorial/Pacbio")
pac_path_out <- file.path(pac_path, "Figures")
pac_path_rds <- file.path(pac_path, "RDS")
pay_the_tax_path <- file.path(base_path, "v2_long_read_tutorial/tax")

pac_tax_path<-file.path(pay_the_tax_path, "silva_nr_v128_train_set.fa.gz")

fn<-"C:/Users/Jorden/Desktop/v2_long_read_tutorial/ccs_test_data.fastq.gz" #sets locaiton of input data
```


## Identification of Primers
 
In this section we need to input the primer information and set up the appropriate "genuspalette" for future plotting purposes. 
Note: After you have concluded the tutorial you will need to change "pacbio_Fw" and "pacbio_rev" to the appropriate primers used in your Pacbio sequencing. Additionally you will need to change the "genusPalette" variable to what microbial taxa you would like to plot at later steps in the tutorial. 
```{r Pacbio 1) Pathing Primer Identification, message = FALSE, warning = FALSE}
pacbio_Fw <- "AGRGTTYGATYMTGGCTCAG" #change to fw primer in sequencing
pacbio_rev <- "RGYTACCTTGTTACGACTT" #change to reverse primer in sequencing
rc <- dada2:::rc #intialized the rc function in the dada2 package
theme_set(theme_bw())
genusPalette <- c(Bacillus="#e41a1c", Enterococcus="#377eb8", Escherichia="#4daf4a", Lactobacillus="#984ea3",
                  Listeria="#ff7f00", Pseudomonas="#ffff33", Salmonella="#a65628", Staphylococcus="#f781bf")
```


## Filtering and Primer Removal

In this section we will be removing the primers and filtering out poor qulaity reads. This will ensure the quality of the reads and assist in downstream taxonomic assignments. After this step the primers in the reads will be removed for further downstream processing in particular it preps the reads for input into the dada2 package. 

```{r Pacbio 2) Filtering and Primer Removal Pacbio, message = FALSE, warning = FALSE}
nop <- file.path(pac_path, "noprimers", basename(fn)) #generates file in the noprimers folder
prim <- removePrimers(fn, nop, primer.fwd=pacbio_Fw, primer.rev=dada2:::rc(pacbio_rev), orient=TRUE,  verbose=TRUE) #removes primers from fastq input file and overwrites file in noprimers folder
hist(nchar(getSequences(nop)), 100) #generates plot of sequences after primer removal

filt <- file.path(pac_path,"filtered", basename(fn)) #generates file in the filtered folder
track <- fastqFilter(nop, filt, minQ=3, minLen=1000, maxLen=1600, maxN=0, rm.phix=FALSE, maxEE=2, verbose=TRUE)#removes primers from fastq input file and overwrites file in filtered folder
hist(nchar(getSequences(filt)), 100) #generates plot of seuqences after quality filtering
```


## Denoising

The next step is arguable the most important part of the tutorial; denoising via dada2 package. This was already loaded into the R environment in the beginning of the workflow so there is no need to worry. This will produce error plots as well as an ASV table which we can then use for taxonomic assingment as well as other helpful information. First we 
dereplicate amplicon sequences and further prep the fastq reads dada2 input. Then we learn error rates specifically for pacbio reads and plot the output error graph.  
The DADA2 algorithm makes use of a parametric error model (err) and every amplicon dataset has a different set of error rates. The learnErrors method learns this error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution. As in many machine-learning problems, the algorithm must begin with an initial guess, for which the maximum possible error rates in this data are used (the error rates if only the most abundant sequence is correct and all the rest are errors).
```{r Pacbio 3) Denoising Pacbio pt1, message = FALSE, warning = FALSE}
drp <- derepFastq(filt, verbose=TRUE)
err <- learnErrors(drp, BAND_SIZE=32, multithread=TRUE, errorEstimationFunction=dada2:::PacBioErrfun) # 10s of seconds
plotErrors(err)
```

The error rates for each possible transition (A→C, A→G, …) are shown. Points are the observed error rates for each consensus quality score. The black line shows the estimated error rates after convergence of the machine-learning algorith. The red line shows the error rates expected under the nominal definition of the Q-score. Here the estimated error rates (black line) are a good fit to the observed rates (points), and the error rates drop with increased quality as expected. Everything looks reasonable and we proceed with confidence.

Now that ats done we will finally run the star of the show dada2; utilizing both of the output files generated from our previous steps. This step will produce read numbers for ccs, primer containing, filtered, and denoised reads.
```{r Pacbio 4) Denoising Pacbio pt2, message = FALSE, warning = FALSE}
dd <- dada(drp, err=err, BAND_SIZE=32, multithread=TRUE) # seconds
cbind(ccs=prim[,1], primers=prim[,2], filtered=track[[2]], denoised=sum(dd$denoised))
dd$clustering[,-1]
```


## Identifying and Removing chimeras

The core dada method corrects substitution and indel errors, but chimeras remain. Fortunately, the accuracy of sequence variants after denoising makes identifying chimeric ASVs simpler than when dealing with fuzzy OTUs. First we need to identify how many if any bimeras ther are:
```{r Pacbio 5) Bimera identification, message = FALSE, warning = FALSE}
bim <- isBimeraDenovo(dd, minFoldParentOverAbundance=3.5) 
# Higher MFPOA to avoid flagging intra-genomic variants
table(bim)
```
As you can see there are are no chimeras (there would be a TRUE column if any chimeras had been identified)!

If there were chimeras present we could remove them and generate a frequency table to determine what the frequency of the chimeras are in the dataset. 
```{r Pacbio 6) Bimera removal, message = FALSE, warning = FALSE}
seqtab.nochim <- removeBimeraDenovo(dd, method="consensus", verbose=TRUE)
dim(seqtab.nochim)
```

## Assigning Taxonomy

Now that we have processed our data to the fullest extent we can plot and pull some interesting conclusions from the data. The first thing one should do is assign taxonomic assignments to the generates ASVs. This canbe done with the phyloseq package in which case you can transition to the dada2 tutorial found here: <https://benjjneb.github.io/dada2/tutorial.html>. However this tutorial will utilize the assignTaxonomy method inate to the dada2 package. To do this we need to generate trained data so that the algorithm knows which taxa belong to which taxonomic assignments. Then we run the main function and voilà! We have taxonomies!
```{r Pacbio 7) Assigning Taxonomy Pacbio, message = FALSE, warning = FALSE}
tax <- assignTaxonomy(dd, pac_tax_path, multithread=TRUE)
tax[,"Genus"] <- gsub("Escherichia/Shigella", "Escherichia", tax[,"Genus"]) # Reformat to be compatible with other data sources
unname(tax)
```